from __future__ import annotations

import csv
import io
import json
import zipfile
from typing import Any, Dict, List, Optional
from datetime import datetime, timezone

from app.services.validation_service import cross_validate_epa
from app.services.emissions_calculator import calculate_emissions
from app.repositories.audit_trail_repository import list_audit_entries
from app.services.storage_service import get_storage


def emissions_to_cevs_format(emissions: Dict[str, Any], company: str) -> Dict[str, Any]:
    """Convert emissions calculation result to CEVS format for SEC filing."""
    totals = emissions.get("totals", {})
    components = emissions.get("components", {})
    
    scope1 = components.get("scope1", {})
    scope2 = components.get("scope2", {})
    
    return {
        "company": company,
        "reporting_period": datetime.now().year - 1,  # Previous year
        "scope1_emissions_tonnes": round(scope1.get("emissions_kg", 0) / 1000.0, 3),
        "scope2_emissions_tonnes": round(scope2.get("emissions_kg", 0) / 1000.0, 3),
        "total_emissions_tonnes": totals.get("emissions_tonnes", 0),
        "calculation_methodology": f"EPA emission factors v{emissions.get('version', '0.1')}",
        "verification_status": "cross-validated",
        "data_sources": ["EPA", "CAMPD"],
        "last_updated": datetime.now(timezone.utc).isoformat(),
        "scope1_details": {
            "fuel_type": scope1.get("fuel_type"),
            "amount": scope1.get("amount"),
            "unit": scope1.get("unit"),
            "emission_factor": scope1.get("factor")
        } if scope1 else None,
        "scope2_details": {
            "kwh": scope2.get("kwh"),
            "grid_region": scope2.get("region"),
            "emission_factor": scope2.get("factor")
        } if scope2 else None
    }


def generate_summary_text(company: str, emissions: Dict[str, Any], validation: Dict[str, Any]) -> str:
    """Generate human-readable summary text for SEC package."""
    totals = emissions.get("totals", {})
    components = emissions.get("components", {})
    
    scope1 = components.get("scope1", {})
    scope2 = components.get("scope2", {})
    
    scope1_tonnes = round(scope1.get("emissions_kg", 0) / 1000.0, 2)
    scope2_tonnes = round(scope2.get("emissions_kg", 0) / 1000.0, 2)
    total_tonnes = totals.get("emissions_tonnes", 0)
    
    # Validation summary
    epa_matches = validation.get("epa", {}).get("matches_count", 0)
    flags = validation.get("flags", [])
    has_mapping = "mapping" in validation
    
    deviation_summary = "None"
    if "quantitative_deviation" in validation:
        deviations = validation["quantitative_deviation"].get("deviations", [])
        if deviations:
            dev = deviations[0]  # First deviation
            deviation_summary = f"PASSED ({dev['deviation_pct']:.1f}% deviation)"
    
    flag_summary = "None" if not flags else f"{len(flags)} issues found"
    
    return f"""ENVOYOU SEC CLIMATE DISCLOSURE SUMMARY
=====================================

Company: {company}
Report Date: {datetime.now().strftime('%Y-%m-%d')}
Reporting Period: {datetime.now().year - 1}

EMISSIONS SUMMARY
-----------------
Scope 1 (Direct): {scope1_tonnes} tonnes CO2e
Scope 2 (Indirect): {scope2_tonnes} tonnes CO2e
Total: {total_tonnes} tonnes CO2e

VALIDATION RESULTS
------------------
EPA Facility Matches: {epa_matches}
Facility Mapping: {'Yes' if has_mapping else 'No'}
Quantitative Validation: {deviation_summary}
Data Quality Flags: {flag_summary}

AUDIT TRAIL
-----------
All calculations and validations are recorded with timestamps,
input parameters, and data sources for SEC compliance and
third-party verification.

For detailed audit records, see audit.csv
For validation details, see validation.json
For structured data, see cevs.json

METHODOLOGY
-----------
Emissions calculated using EPA emission factors v{emissions.get('version', '0.1')}
Cross-validated against EPA Envirofacts and CAMPD databases
Audit trail maintained for forensic-grade traceability

Generated by Envoyou SEC API
{datetime.now(timezone.utc).isoformat()}
"""


def cevs_to_sec_json(result: Dict[str, Any]) -> Dict[str, Any]:
    """Map compute_cevs_for_company() result into a SEC-friendly JSON shape.
    This is a minimal scaffold and can be extended to match final schema.
    """
    return {
        "company": result.get("company"),
        "country": result.get("country"),
        "summary": {
            "score": result.get("score"),
            "components": result.get("components", {}),
        },
        "data_sources": result.get("sources", {}),
        "technical_notes": {
            "methodology": "Composite score based on ISO presence, EPA matches, renewables proxy, pollution trends, and CAMPD penalties.",
            "version": "v0.1.0",
        },
    }


def audit_trails_to_csv(entries: List[Dict[str, Any]]) -> str:
    """Export list of audit trail dicts to CSV string."""
    if not entries:
        return ""
    columns = [
        "id",
        "timestamp",
        "company_cik",
        "source_file",
        "calculation_version",
        "s3_path",
        "gcs_path",
        "notes",
    ]
    buf = io.StringIO()
    writer = csv.DictWriter(buf, fieldnames=columns)
    writer.writeheader()
    for e in entries:
        writer.writerow({k: e.get(k) for k in columns})
    return buf.getvalue()


def build_and_upload_sec_package(*, company: str, payload: Dict[str, Any], db) -> Dict[str, Any]:
    """Build a SEC export package (zip) containing:
    - cevs.json (calculated emissions data)
    - validation.json (cross-validation EPA)
    - audit.csv (audit entries for company)
    - summary.txt (human-readable summary)
    - readme.txt (timestamp and basic info)

    Upload using configured storage and return URL + filenames.
    """
    # Calculate emissions for CEVS
    emissions = calculate_emissions(payload)
    cevs_data = emissions_to_cevs_format(emissions, company)
    
    # Build validation
    validation = cross_validate_epa(payload, db=db, state=payload.get("state"))

    # Fetch audit entries
    audits = list_audit_entries(db, company_cik=company, limit=1000)
    audit_csv = audit_trails_to_csv([a.to_dict() for a in audits])
    
    # Generate summary
    summary_text = generate_summary_text(company, emissions, validation)

    # Build zip in memory
    zip_buf = io.BytesIO()
    with zipfile.ZipFile(zip_buf, mode="w", compression=zipfile.ZIP_DEFLATED) as z:
        # cevs.json
        z.writestr("cevs.json", json.dumps(cevs_data, ensure_ascii=False, indent=2))
        # validation.json
        z.writestr("validation.json", json.dumps(validation, ensure_ascii=False, indent=2))
        # audit.csv
        z.writestr("audit.csv", audit_csv)
        # summary.txt
        z.writestr("summary.txt", summary_text)
        # readme
        ts = datetime.now(timezone.utc).isoformat()
        readme = f"SEC Export Package\nCompany: {company}\nGenerated: {ts}\nFiles: cevs.json, validation.json, audit.csv, summary.txt\n"
        z.writestr("README.txt", readme)
    zip_bytes = zip_buf.getvalue()

    # Upload
    storage = get_storage()
    fname = f"{company.replace(' ', '_').lower()}_sec_package_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip"
    url = storage.upload_bytes(fname, zip_bytes, content_type="application/zip")

    return {
        "url": url,
        "filename": fname,
        "size_bytes": len(zip_bytes),
        "files": ["cevs.json", "validation.json", "audit.csv", "summary.txt", "README.txt"],
    }
